{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJxpzeDWafQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8f5149-4d7b-4e6f-cb98-abf4aa0d7310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install emoji\n",
        "!pip install tf\n",
        "!pip install -q gdown\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import emoji\n",
        "import string\n",
        "import re #regex library\n",
        "# import word_tokenize & FreqDist from NLTK\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D,MaxPooling1D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Read the Dataset"
      ],
      "metadata": {
        "id": "kWLM9VC5mCaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "!gdown --id '1zTbVRzqa71gKuxHvx2Kbrgz6rQc9ikTL'\n",
        "df = pd.read_csv(\"/content/ISOT.csv\")"
      ],
      "metadata": {
        "id": "BKUNFMyjft3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49f8003-b90d-4c1e-c0e1-fa803bc04ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zTbVRzqa71gKuxHvx2Kbrgz6rQc9ikTL\n",
            "To: /content/ISOT.csv\n",
            "100% 117M/117M [00:01<00:00, 66.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load the GloVe and Word2Vec Model"
      ],
      "metadata": {
        "id": "rP7hKM26mEf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GloVe embeddings from a text file\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = coefs\n",
        "    return embeddings\n",
        "!gdown --id '1ghIpaPAP1b8CWQUwFBiC4ucQs1-ASAC_'\n",
        "glove_embeddings_path = '/content/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_embeddings_path)\n",
        "\n",
        "# Set the dimensions of the GloVe embeddings\n",
        "glove_embedding_dim = len(next(iter(glove_embeddings.values())))\n",
        "\n"
      ],
      "metadata": {
        "id": "Icnxcb2rlABB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c1ff3f-a777-48cd-d1ae-b63d5eb18b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ghIpaPAP1b8CWQUwFBiC4ucQs1-ASAC_\n",
            "To: /content/glove.6B.300d.txt\n",
            "100% 1.04G/1.04G [00:08<00:00, 122MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "print(gensim.__version__)\n",
        "# Load Pretrained Word Embeddings (Word2Vec)\n",
        "!gdown --id '1SkL4YikSgBeIsEe8idl_ktlVdah1jm8e'\n",
        "word_embeddings = KeyedVectors.load_word2vec_format('/content/GoogleNews-vectors-negative300.bin',binary=True)"
      ],
      "metadata": {
        "id": "XgJxnn7rlICx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d54469c-1f5c-4c46-f376-49a1f8c0366e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3.1\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SkL4YikSgBeIsEe8idl_ktlVdah1jm8e\n",
            "To: /content/GoogleNews-vectors-negative300.bin\n",
            "100% 3.64G/3.64G [00:30<00:00, 120MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of word embeddings\n",
        "embedding_dimension = word_embeddings.vectors.shape[1]\n",
        "\n",
        "print(\"Word Embedding Dimension:\", embedding_dimension)"
      ],
      "metadata": {
        "id": "NYkoOOT-lNl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d93b9a7-e7d5-46bf-e15d-b099f0d5becf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Embedding Dimension: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split The Dataset"
      ],
      "metadata": {
        "id": "1gqPlAiQmJ5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2 ,random_state=42)"
      ],
      "metadata": {
        "id": "qUZifk7QkzhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementation"
      ],
      "metadata": {
        "id": "1t9KvcxymMUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and convert text to sequences\n",
        "max_sequence_length = 100  # Define the maximum length of input sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "word_index = tokenizer.word_index\n",
        "num_words = len(word_index) + 1\n",
        "X_padded_train = pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
        "X_padded_test = pad_sequences(sequences_test, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "7vR_rlr3kt0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the margin loss function\n",
        "def margin_loss(y_true, y_pred):\n",
        "    margin = K.constant(0.1)\n",
        "    y_true_float = K.cast(y_true, dtype='float32')  # Convert y_true to float32\n",
        "    squared_difference_pos = K.square(K.maximum(0.9 - y_pred, 0))\n",
        "    squared_difference_neg = K.square(K.maximum(y_pred - 0.1, 0))\n",
        "    loss_pos = K.mean(y_true_float * squared_difference_pos)\n",
        "    loss_neg = K.mean((1 - y_true_float) * squared_difference_neg)\n",
        "    total_loss = loss_pos + lambda_val * loss_neg\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "T6UmYRSHlOCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architectures\n",
        "embedding_dim = 300\n",
        "max_sequence_length = 100\n",
        "lambda_val = 0.7  # Lambda value for margin loss"
      ],
      "metadata": {
        "id": "O8XPmdA_lRIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the embedding matrix\n",
        "embedding_matrix = np.zeros((num_words, glove_embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "fq4JSxaM03BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Static"
      ],
      "metadata": {
        "id": "rotKmdsNlUJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Static Model with GloVe\n",
        "static_model = Sequential()\n",
        "static_model.add(Embedding(num_words, embedding_dim, input_length=max_sequence_length, trainable=False, weights=[embedding_matrix]))\n",
        "static_model.add(Conv1D(128, 3, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "static_model.add(MaxPooling1D(2))\n",
        "static_model.add(Flatten())\n",
        "static_model.add(Dense(128, activation='relu'))\n",
        "static_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "learning_rate = 0.001\n",
        "# Set the margin loss as the loss function\n",
        "static_model.compile(loss=margin_loss, optimizer=Adam(learning_rate), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xO9TNKNylRrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Non-Static"
      ],
      "metadata": {
        "id": "bNmPMDTLlafH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-Static Model with GloVe\n",
        "non_static_model = Sequential()\n",
        "non_static_model.add(Embedding(num_words, embedding_dim, input_length=max_sequence_length, trainable=True, weights=[embedding_matrix]))\n",
        "non_static_model.add(Conv1D(128, 3, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "non_static_model.add(MaxPooling1D(2))\n",
        "non_static_model.add(Flatten())\n",
        "non_static_model.add(Dense(128, activation='relu'))\n",
        "non_static_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Set the margin loss as the loss function\n",
        "non_static_model.compile(loss=margin_loss, optimizer=Adam(learning_rate), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ggm4xlIOlVpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Multichannel"
      ],
      "metadata": {
        "id": "LaiJUEctlhO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multichannel Model with GloVe\n",
        "multichannel_model = Sequential()\n",
        "multichannel_model.add(Embedding(num_words, embedding_dim, input_length=max_sequence_length, trainable=False, weights=[embedding_matrix]))\n",
        "multichannel_model.add(Conv1D(128, 3, activation='relu'))\n",
        "multichannel_model.add(MaxPooling1D(2))\n",
        "multichannel_model.add(Conv1D(128, 3, activation='relu'))\n",
        "multichannel_model.add(MaxPooling1D(2))\n",
        "multichannel_model.add(Flatten())\n",
        "\n",
        "# Add the second channel with GloVe embeddings\n",
        "multichannel_model.add(Embedding(num_words, embedding_dim, input_length=max_sequence_length, trainable=True, weights=[embedding_matrix]))\n",
        "multichannel_model.add(Conv1D(128, 3, activation='relu'))\n",
        "multichannel_model.add(MaxPooling1D(2))\n",
        "multichannel_model.add(Flatten())\n",
        "\n",
        "multichannel_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "multichannel_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-7)\n",
        "learning_rate = 0.001\n",
        "# Set the margin loss as the loss function\n",
        "multichannel_model.compile(loss=margin_loss, optimizer=Adam(learning_rate), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JThmrl6ilfmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "KwpDZV57lvZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the models\n",
        "static_model.fit(X_padded_train, y_train, batch_size=25, epochs=10, validation_data=(X_padded_test, y_test))"
      ],
      "metadata": {
        "id": "QD7oV-Dxlnax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1111246b-30f3-4c26-8d84-69d4fd786719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1437/1437 [==============================] - 16s 10ms/step - loss: 0.0768 - accuracy: 0.9518 - val_loss: 0.0297 - val_accuracy: 0.9713\n",
            "Epoch 2/10\n",
            "1437/1437 [==============================] - 15s 10ms/step - loss: 0.0281 - accuracy: 0.9687 - val_loss: 0.0285 - val_accuracy: 0.9553\n",
            "Epoch 3/10\n",
            "1437/1437 [==============================] - 15s 10ms/step - loss: 0.0242 - accuracy: 0.9709 - val_loss: 0.0274 - val_accuracy: 0.9687\n",
            "Epoch 4/10\n",
            "1437/1437 [==============================] - 15s 11ms/step - loss: 0.0228 - accuracy: 0.9734 - val_loss: 0.0254 - val_accuracy: 0.9633\n",
            "Epoch 5/10\n",
            "1437/1437 [==============================] - 15s 10ms/step - loss: 0.0218 - accuracy: 0.9741 - val_loss: 0.0227 - val_accuracy: 0.9657\n",
            "Epoch 6/10\n",
            "1437/1437 [==============================] - 15s 10ms/step - loss: 0.0203 - accuracy: 0.9743 - val_loss: 0.0193 - val_accuracy: 0.9749\n",
            "Epoch 7/10\n",
            "1437/1437 [==============================] - 15s 10ms/step - loss: 0.0204 - accuracy: 0.9743 - val_loss: 0.0209 - val_accuracy: 0.9752\n",
            "Epoch 8/10\n",
            "1437/1437 [==============================] - 15s 10ms/step - loss: 0.0198 - accuracy: 0.9766 - val_loss: 0.0212 - val_accuracy: 0.9742\n",
            "Epoch 9/10\n",
            "1437/1437 [==============================] - 15s 10ms/step - loss: 0.0188 - accuracy: 0.9786 - val_loss: 0.0190 - val_accuracy: 0.9768\n",
            "Epoch 10/10\n",
            "1437/1437 [==============================] - 15s 11ms/step - loss: 0.0184 - accuracy: 0.9790 - val_loss: 0.0208 - val_accuracy: 0.9743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29f8365f00>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_static_model.fit(X_padded_train, y_train, batch_size=25, epochs=10, validation_data=(X_padded_test, y_test))"
      ],
      "metadata": {
        "id": "jsg1PciqloYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87ab19d-d5fe-4f6b-f9e3-5da2f125d3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1437/1437 [==============================] - 602s 418ms/step - loss: 0.0676 - accuracy: 0.9428 - val_loss: 0.0194 - val_accuracy: 0.9841\n",
            "Epoch 2/10\n",
            "1437/1437 [==============================] - 602s 419ms/step - loss: 0.0110 - accuracy: 0.9897 - val_loss: 0.0113 - val_accuracy: 0.9854\n",
            "Epoch 3/10\n",
            "1437/1437 [==============================] - 604s 420ms/step - loss: 0.0074 - accuracy: 0.9938 - val_loss: 0.0090 - val_accuracy: 0.9892\n",
            "Epoch 4/10\n",
            "1437/1437 [==============================] - 616s 428ms/step - loss: 0.0058 - accuracy: 0.9958 - val_loss: 0.0097 - val_accuracy: 0.9878\n",
            "Epoch 5/10\n",
            "1437/1437 [==============================] - 626s 436ms/step - loss: 0.0048 - accuracy: 0.9965 - val_loss: 0.0284 - val_accuracy: 0.9379\n",
            "Epoch 6/10\n",
            "1437/1437 [==============================] - 627s 436ms/step - loss: 0.0040 - accuracy: 0.9977 - val_loss: 0.0073 - val_accuracy: 0.9890\n",
            "Epoch 7/10\n",
            "1437/1437 [==============================] - 627s 436ms/step - loss: 0.0036 - accuracy: 0.9978 - val_loss: 0.0089 - val_accuracy: 0.9884\n",
            "Epoch 8/10\n",
            "1437/1437 [==============================] - 625s 435ms/step - loss: 0.0035 - accuracy: 0.9979 - val_loss: 0.0113 - val_accuracy: 0.9844\n",
            "Epoch 9/10\n",
            "1437/1437 [==============================] - 624s 434ms/step - loss: 0.0033 - accuracy: 0.9983 - val_loss: 0.0077 - val_accuracy: 0.9886\n",
            "Epoch 10/10\n",
            "1437/1437 [==============================] - 622s 433ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.0105 - val_accuracy: 0.9859\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29f814d450>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multichannel_model.fit(X_padded_train, y_train, batch_size=25, epochs=10, validation_data=(X_padded_test, y_test), callbacks=[reduce_lr])"
      ],
      "metadata": {
        "id": "N1HEf_7-lpRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366e10a1-dd2f-4cd7-e370-4a3c3f4b461f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv1d_44/kernel:0', 'conv1d_44/bias:0', 'conv1d_45/kernel:0', 'conv1d_45/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv1d_44/kernel:0', 'conv1d_44/bias:0', 'conv1d_45/kernel:0', 'conv1d_45/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv1d_44/kernel:0', 'conv1d_44/bias:0', 'conv1d_45/kernel:0', 'conv1d_45/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv1d_44/kernel:0', 'conv1d_44/bias:0', 'conv1d_45/kernel:0', 'conv1d_45/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1437/1437 [==============================] - 900s 626ms/step - loss: 0.1315 - accuracy: 0.6733 - val_loss: 0.1161 - val_accuracy: 0.7012 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "1437/1437 [==============================] - 902s 628ms/step - loss: 0.1152 - accuracy: 0.6938 - val_loss: 0.1132 - val_accuracy: 0.6993 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "1437/1437 [==============================] - 891s 620ms/step - loss: 0.1127 - accuracy: 0.6991 - val_loss: 0.1116 - val_accuracy: 0.6986 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "1437/1437 [==============================] - 896s 624ms/step - loss: 0.1113 - accuracy: 0.7012 - val_loss: 0.1107 - val_accuracy: 0.7001 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "1437/1437 [==============================] - 890s 620ms/step - loss: 0.1097 - accuracy: 0.7040 - val_loss: 0.1090 - val_accuracy: 0.6981 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "1437/1437 [==============================] - 892s 621ms/step - loss: 0.1086 - accuracy: 0.7059 - val_loss: 0.1078 - val_accuracy: 0.7091 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "1437/1437 [==============================] - 912s 635ms/step - loss: 0.1073 - accuracy: 0.7081 - val_loss: 0.1077 - val_accuracy: 0.6965 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "1437/1437 [==============================] - 945s 658ms/step - loss: 0.1062 - accuracy: 0.7066 - val_loss: 0.1059 - val_accuracy: 0.7077 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "1437/1437 [==============================] - 907s 631ms/step - loss: 0.1055 - accuracy: 0.7087 - val_loss: 0.1054 - val_accuracy: 0.7129 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "1437/1437 [==============================] - 895s 623ms/step - loss: 0.1051 - accuracy: 0.7119 - val_loss: 0.1052 - val_accuracy: 0.7004 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29f86a1db0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation"
      ],
      "metadata": {
        "id": "Uv-0hEcGl0af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the models\n",
        "static_scores = static_model.evaluate(X_padded_test, y_test, verbose=0)\n",
        "non_static_scores = non_static_model.evaluate(X_padded_test, y_test, verbose=0)\n",
        "multichannel_scores = multichannel_model.evaluate(X_padded_test, y_test, verbose=0)\n",
        "\n",
        "# Print the accuracy scores\n",
        "print(\"Static Model Accuracy: %.2f%%\" % (static_scores[1] * 100))\n",
        "print(\"Non-Static Model Accuracy: %.2f%%\" % (non_static_scores[1] * 100))\n",
        "print(\"Multichannel Model Accuracy: %.2f%%\" % (multichannel_scores[1] * 100))"
      ],
      "metadata": {
        "id": "blFU6DTclz7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dac2f5d-1b60-4d92-fe53-f6043d1e41e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Static Model Accuracy: 97.43%\n",
            "Non-Static Model Accuracy: 98.59%\n",
            "Multichannel Model Accuracy: 70.04%\n"
          ]
        }
      ]
    }
  ]
}